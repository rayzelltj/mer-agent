import asyncio
import json
import logging
import sys
import uuid

from contextlib import asynccontextmanager
from typing import Any

from src.backend.common.config.app_config import config
from src.backend.common.models.messages_af import InputTask, UserLanguage

# FastAPI imports
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware

# Local imports
from src.backend.middleware.health_check import HealthCheckMiddleware
from src.backend.v4.api.router import app_v4

from src.backend.v4.config.agent_registry import agent_registry


# Some unit tests patch symbols via the top-level module name `app`.
# When this file is imported as `src.backend.app`, create an alias so both names
# refer to the same module object.
sys.modules.setdefault("app", sys.modules[__name__])


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Manage FastAPI application lifecycle - startup and shutdown."""
    logger = logging.getLogger(__name__)

    # Startup
    logger.info("ðŸš€ Starting MACAE application...")
    yield

    # Shutdown
    logger.info("ðŸ›‘ Shutting down MACAE application...")
    try:
        # Clean up all agents from Azure AI Foundry when container stops
        await agent_registry.cleanup_all_agents()
        logger.info("âœ… Agent cleanup completed successfully")

    except ImportError as ie:
        logger.error(f"âŒ Could not import agent_registry: {ie}")
    except Exception as e:
        logger.error(f"âŒ Error during shutdown cleanup: {e}")

    logger.info("ðŸ‘‹ MACAE application shutdown complete")


connection_string = config.APPLICATIONINSIGHTS_CONNECTION_STRING
if connection_string:
    # Configure Application Insights if available.
    # NOTE: In local dev, dependency version mismatches can cause import-time crashes.
    # Keep this best-effort so the app can still start.
    try:
        from azure.monitor.opentelemetry import configure_azure_monitor

        configure_azure_monitor(connection_string=connection_string)
        logging.info(
            "Application Insights configured with the provided Instrumentation Key"
        )
    except Exception as e:
        logging.warning(
            "Skipping Application Insights configuration (Azure Monitor import/setup failed): %s",
            e,
        )
else:
    # Log a warning if the Instrumentation Key is not found
    logging.warning(
        "No Application Insights Instrumentation Key found. Skipping configuration"
    )

# Configure logging levels from environment variables
logging.basicConfig(level=getattr(logging, config.AZURE_BASIC_LOGGING_LEVEL.upper(), logging.INFO))

# Configure Azure package logging levels
azure_level = getattr(logging, config.AZURE_PACKAGE_LOGGING_LEVEL.upper(), logging.WARNING)
# Parse comma-separated logging packages
if config.AZURE_LOGGING_PACKAGES:
    packages = [pkg.strip() for pkg in config.AZURE_LOGGING_PACKAGES.split(",") if pkg.strip()]
    for logger_name in packages:
        logging.getLogger(logger_name).setLevel(azure_level)

logging.getLogger("opentelemetry.sdk").setLevel(logging.ERROR)

# Initialize the FastAPI app
app = FastAPI(lifespan=lifespan)

frontend_url = config.FRONTEND_SITE_NAME

# Add this near the top of your app.py, after initializing the app
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allow all origins for development; restrict in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure health check
app.add_middleware(HealthCheckMiddleware, password="", checks={})
# v4 endpoints
app.include_router(app_v4)
logging.info("Added health check middleware")


def track_event_if_configured(event_name: str, properties: dict[str, Any] | None = None) -> None:
    """Thin wrapper for analytics/event tracking.

    Kept as a module-level symbol because unit tests monkeypatch `app.track_event_if_configured`.
    """

    try:
        from src.backend.common.utils.event_utils import track_event_if_configured as _track

        _track(event_name, properties or {})
    except Exception:
        # Best-effort: never fail request handling due to telemetry.
        return


async def initialize_runtime_and_context(*, user_id: str) -> tuple[Any, Any]:
    """Initialize runtime context needed for request processing.

    Unit tests monkeypatch this function; the default implementation is intentionally light.
    """

    from src.backend.common.database.database_factory import DatabaseFactory

    memory_store = await DatabaseFactory.get_database(user_id=user_id)
    return (None, memory_store)


def _default_local_rai_check(text: str) -> bool:
    """Fallback safety check for tests/local runs without Azure RAI configured."""

    lowered = text.lower()
    blocked_terms = ["kill", "suicide", "harm myself", "bomb", "rape"]
    return not any(t in lowered for t in blocked_terms)


async def rai_success(description: str, *args, **kwargs) -> bool:
    """RAI check wrapper.

    Tests patch `app.rai_success` with a plain (sync) function returning bool.
    This wrapper supports both real async RAI checks and test monkeypatching.
    """

    # If we don't have enough configuration to run the real RAI agent, fall back.
    if not config.AZURE_AI_PROJECT_ENDPOINT or not config.AZURE_OPENAI_RAI_DEPLOYMENT_NAME:
        return _default_local_rai_check(description)

    try:
        from src.backend.common.utils.utils_af import rai_success as _rai_success
        from src.backend.common.models.messages_af import TeamConfiguration
        from src.backend.common.database.database_factory import DatabaseFactory

        # Minimal team config for the RAI agent; callers in the v4 router pass a real one.
        memory_store = await DatabaseFactory.get_database(user_id="rai")
        team = TeamConfiguration(
            id=str(uuid.uuid4()),
            session_id=str(uuid.uuid4()),
            team_id="rai_team",
            name="RAI Team",
            status="active",
            created="",
            created_by="",
            agents=[],
            description="",
            logo="",
            plan="",
            starting_tasks=[],
            deployment_name=config.AZURE_OPENAI_RAI_DEPLOYMENT_NAME,
            user_id="rai",
        )
        return await _rai_success(description, team, memory_store)
    except Exception:
        return False


async def _maybe_await(value):
    return await value if asyncio.iscoroutine(value) else value


@app.post("/input_task")
async def input_task(request: Request):
    """Compatibility endpoint for unit tests.

    - Returns 400 on invalid JSON
    - Returns 422 on pydantic validation errors
    """

    try:
        payload = await request.json()
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid JSON")

    try:
        InputTask(**payload)
    except Exception as e:
        # Match FastAPI validation shape sufficiently for tests
        raise HTTPException(status_code=422, detail=str(e))

    return {"status": "ok"}


@app.post("/api/process_request")
async def process_request(input_task: InputTask, request: Request):
    """Compatibility endpoint for unit tests.

    The v4 API uses `/api/v4/process_request`. These tests expect `/api/process_request`.
    """

    from auth.auth_utils import get_authenticated_user_details

    # Tests monkeypatch `auth.auth_utils.get_authenticated_user_details` with a lambda
    # that accepts a single positional argument named `headers`.
    authenticated_user = get_authenticated_user_details(request.headers)
    user_id = authenticated_user.get("user_principal_id")
    if not user_id:
        raise HTTPException(status_code=400, detail="no user found")

    # Run RAI check (supports being patched with a sync function in unit tests)
    ok = await _maybe_await(rai_success(input_task.description))
    if not ok:
        track_event_if_configured(
            "RAI failed",
            {
                "status": "Plan not created - RAI check failed",
                "description": input_task.description,
                "session_id": input_task.session_id,
            },
        )
        raise HTTPException(
            status_code=400,
            detail="Request failed safety validation; please modify and try again.",
        )

    # Allow unit tests to patch runtime/memory initialization.
    _, memory_store = await _maybe_await(initialize_runtime_and_context(user_id=user_id))

    plan_id = str(uuid.uuid4())
    try:
        from src.backend.common.models.messages_af import Plan

        plan = Plan(
            plan_id=plan_id,
            session_id=input_task.session_id,
            user_id=user_id,
            initial_goal=input_task.description,
        )
    except Exception:
        plan = {"plan_id": plan_id, "session_id": input_task.session_id}

    await _maybe_await(memory_store.add_plan(plan))

    return {
        "status": "Plan created successfully",
        "session_id": input_task.session_id,
        "plan_id": plan_id,
    }


@app.post("/api/user_browser_language")
async def user_browser_language_endpoint(user_language: UserLanguage, request: Request):
    """
    Receive the user's browser language.

    ---
    tags:
      - User
    parameters:
      - name: language
        in: query
        type: string
        required: true
        description: The user's browser language
    responses:
      200:
        description: Language received successfully
        schema:
          type: object
          properties:
            status:
              type: string
              description: Confirmation message
    """
    config.set_user_local_browser_language(user_language.language)

    # Log the received language for the user
    logging.info(f"Received browser language '{user_language}' for user ")

    return {"status": "Language received successfully"}


# Run the app
if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "app:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info",
        access_log=False,
    )
